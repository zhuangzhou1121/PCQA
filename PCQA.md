

[TOC]

# 主观实验

主观实验主要分为两个部分：数据库构建和主观测试

## 数据库构建

选取点云：密集程度、实例种类、几何结构、颜色特征等

添加失真：几何失真、颜色失真、几何颜色混合失真等

目前适合用于点云质量评价研究的数据库还很少，Stanford 3D、MPEG、JPEG Pleno、IRPC（6，54）、SJTU-PCQA（10，420）、WPC（20，740）、WPC2.0(16，400)（这种只有VPCC失真，因此不适合作为一个通用的质量评价数据库）、BASICS（75，1494）、LS-PCQA（104，22568）、SIAT(20，340)、PointXR(5，40)。（后两个使用的是主动交互）

![image-20240408145800077](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408145800077.png)

## 主观测试

而对于主观测试的具体条件，在点云领域没有针对主观测试条件发布标准建议。

（1）首先，与绝对类别评分(Absolute Category Rating, ACR)和成对比较(Pairwise Comparison, PC)相比，实验表明 DSIS 得到的分数与失真程度表现更一致，**DSIS**更为常用。

（2）由于点云是一种 3D 数据，它可以通过普通的平面屏幕进行呈现，也可以通过 VR 设备进行沉浸式呈现。

（3）交互方式有互动交互和被动交互，较为常用的是**被动交互**。

（4）目前渲染方式主要有两种，一种是基于点的渲染，通过把点变成有面积的基础几何体（比如圆圈、 方形、球体，立方体等）来进行渲染。另一种方式是基于网格（Mesh）的渲染方式，即通过表面重建算法（比如泊松表面重建）构建多边形网格来进行渲染。

---

# 客观实验

1、点云的客观质量评价方法主要是**全参考质量评价**。分为两类，

一是基于3D空间特征的质量评价模型(3D属性建模)，

二是投影后通过图像领域的质量评价算法来衡量误差的方法。（这一类包括投影成图像或者渲染成视频）

2、**部分参考和无参考**质量评价模型依赖于全参考质量评价模型的发展以及点云本身特征的研究，且基于一个大型数据库的训练，因此这类质量评价模型的研究还较少。

3、部分参考质量评价模型较多用在压缩传输中，只传输原始点云的特征，让接收端对重建的点云质量进行衡量。

---

## 全参考质量评估

### 基于3D空间特征的质量评价模型(3D属性建模)

1、（基于3D空间特征的质量评价）这个方法是指通过比较3D区域中的对应点或者对应区域的**相似性**来进行质量评价的方法。这类方法直接对比3D空间中的**点间距离**，**几何表面相似度**，**颜色信息统计**等特征来进行质量评价，下面对这些方法进行介绍。（使用mamba模型提取点云特征，直接对点云特征进行处理，属于基于3D空间特征的质量评价）

#### 点间距离

全参考度量：点对点(p2po)、点对平面(p2pl)、点对网格(p2m)、面对平面(pl2pl)等。

通过计算参考点云和扭曲点云的几何特征差异得到以下经典的FR度量。这些指标使用点云中直接可用的数据块来计算几何误差并得出质量等级。

point-to-point（通过欧式几何距离评估几何失真，对在扭曲和参考点云中，直接量化扭曲点云相对于参考点云存在的几何偏差。）。

point-to-plane（通过沿法向量方向的投影误差评估几何失真，减少了对复杂表面结构或点云重建的依赖）。

plane-to-plane(通过计算局部表面近似的相似性来预测几何失真，评估点云内切面之间的角度对齐来量化质量，从而提供客观的质量度量)。

point-to-surface（或者 point-to-mesh）的方法首先进行表面重建，然后计算点到对应面的距离作为衡量，由于该方法极其依赖于表面的重建效果， 因此不太常用。

Javaheri在中提出了一种 point-to-distribution的方法，该方法提出了一种新的对应关系，基于马氏距离来计算点云中的一个点和另一个点云中的一小块区域中的点的误差。

上述提到的方法都**只对几何失真进行了衡量**，为了衡量点云的颜色失真，可以首先将RGB转为YUV，并针对各个颜色通道分别计算距离。

除欧几里得距离外，一些广义指标，如局部曲率统计量、PSNR、Hausdorff距离、Mahalanobis距离也被应用于点云间质量误差的计算。虽然这些FR指标提供了清晰的定义和直接的推理程序，但它们可能无法准确捕获HVS感知到的点云的真实质量，特别是在处理显示纹理失真的点云时。

#### 几何表面相似度和颜色信息统计

1、基于图相似性（**GraphSIM**）的质量评价方法。其主要创新点在于使用点云的几何特征构建局部图表达方式，将点云的颜色特征视为图上的信号并提取**几何-颜色联合特征**进行失真评价。

2、对GraphSIM进行扩展提出更加鲁棒的 **MS-GraphSIM**。在GraphSIM的基础上，根据上述三种视觉现象（颜色模糊，细节丢失以及尺度变换）对每个关键点所在的球型域的依次进行了颜色低通滤波、几何降采样、区域收缩，通过重复操作即可构建多个新的尺度的点云图表达方式，然后对不同尺度下计算出的评价分数进行池化得到最终评价分数。

3、受到图像质量评价算法SSIM的影响，Meynet在中提出了一种**基于局部曲率统计**的质量评价方法**PC-MSDM**，作者通过**提取局部曲率信息来对比**两个点云的几何结构特征。

4、Alexiou在提出了**PointSSIM**的方法，综合考虑了几何、法向量、曲率和颜色四个属性，然后评估几何和颜色的特征的相似度，并将其结合起来产生总体客观分数。

5、PCQM:该方法是一个最优加权线性组合，由基于几何和颜色特征组成。

6、Viola在提出了一种利用颜色相关直方图（Color Correlogram）进行统计分析的质量评价的方法。

7、最近，局部二值模式(LBP)、感知颜色距离模式(PCDP)[50]和局部亮度模式(LLP)描述符的一种变体的统计数据被引入该领域。

8、还有一些弹性势能相似(EPES)模型、BitDance、CPC-GSCT度量等方法。

---

### 基于投影的全参考质量评价模型

直接采用点云计算量大，鉴于图像领域的质量评价方法已经比较成熟，因此，很多研究试图将点云投影为2D图像，并采用IQA的方法来进行评价。（实际上的问题就是把点云投影到图像上，利用传统的iqas指标进行测就行了，问题就在如何投影，在iqas测之前的准备工作是什么，方法是什么，有什么创新之处）（体素化、正交六面投影、分配权重、patch、利用多视点距离等等）（使用mamba获得点云特征，然后利用iqa方法也是可以的吧）

1、Queiroz 在（Motion-compensated compression of dynamic voxelized point clouds）(动态体素化点云的运动补偿压缩)中对于动态点云的压缩过程中较早的使用了基于投影的质量评价方法，他先将点云进行**体素化处理，然后采用正交六面投影的方法， 计算投影后的图片之间的 MSE 和 PSNR 作为评价标准**。<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408152143771.png" alt="image-20240408152143771" style="zoom:25%;" />这个图就是体素化过程的一个示例，将三维模型从连续空间转换为离散空间表示的过程，降低了渲染成本。（当点体素化时，它们被表示为立方体体积元素，即体素，体素可以被占用，也可以不被占用。当它们被占用时，将显示由相应点给出的颜色值。如果同一区域内有多个点，则体素的颜色由这些点的颜色值的平均值给出。)

2、Alexiou 在（A novel methodology for quality assessment of voxelized point clouds）(体素化点云质量评价的新方法)中同样采用了**正交六面投影**的方式，但他<u>同时测试了IQA中的多个方法 （ PSNR 、 PSNR-HVS 、 PSNR-HVS-M 、 SSIM 、 MSSSIM、VIFP），并对六个面的分数进行平均池化</u>，试验结果表明，基于投影的方法明显好于基于点到点之间距离的方法。之后，该作者又在（Exploiting user interactivity in quality assessment of point cloud imaging）（在点云成像质量评估中利用用户交互性）中研究了不同的投影角度及投影面个数对于结果的影响，其中各个投影角度的分数权重通过主观实验中被测试者的观察时间得到，最后发现，<u>改变投影角度并增加投影面数量并不会对结果产生很大影响，即使只有正面的单视角投影也可以达到很好的效果。</u>（这些都未细看，只得到了这么个结论，第五条文章里也有说六个面可能表达不完整，但这篇论文里提到的方法增加投影面对结果影响不大）

3、原则上，3D模型的不同透视图可能具有不同的重要性。类似地，可以对用于预测3D模型视觉质量的视图**分配非均匀加权函数**。根据主观评价实验中记录的交互性数据，为模型的每个视图分配重要性权重。并应用重要性权重计算客观得分。

4、Predicting the Perceptual Quality of Point Cloud: A 3D-to-2D Projection-Based Exploration（预测点云的感知质量：基于3d到2d投影的探索）提出了一种基于投影的方法，选择将3D点云投影到立方体的六个垂直图像平面上（如图的前、后、左、右、上、下平面/视图），以获得来自不同投影平面的六对彩色纹理图像和相应的深度图像，将原生RGB样本映射到更符合HVS的高斯颜色空间的颜色空间转换。并在所有投影平面中聚合基于图像的全局和局部特征，以获得最终的客观指数。<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408154937691.png" alt="image-20240408154937691" style="zoom:50%;" />

5、Subjective Quality Database and Objective Study of Compressed Point Clouds with 6DoF Head-mounted Display (6自由度头戴式显示器压缩点云主观质量数据库与客观研究)提出了两种基于投影的客观质量评价方法：

基于加权视图投影的模型和基于patch投影的模型。

（1）基于加权视图投影的模型：广泛使用的基于投影的方法将点云投影到边界框的六个平面上，无论不同视图的重要性如何，都将每个平面视为一个平等的角色。通过主观实验，发现边界框平面的大小可能与视觉质量有关，越大的区域越有可能通过显示内容的更多细节来吸引被试的视觉注意力。提出了一种基于加权视图投影的PCQA方法，**将一个视图的权重设置为一个平面的大小与边界框上六个平面的面积之和的比率**。该模型易于操作，节省时间，计算成本低。然而，由于观察者可以从每个角度看到一个点云，六个平面不足以表示人眼感知的所有视图，因此视图投影可能会导致遮挡，并且几何形状可能不太敏感或表达不完整。

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408160012840.png" alt="image-20240408160012840" style="zoom:33%;" />

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408160111219.png" alt="image-20240408160111219" style="zoom:33%;" />

（2）基于patch投影的模型：为了发现点云不同视图的更多细节，减少视图投影带来的自遮挡，最好将点云分割成更小的部分，然后将它们投影到平面上。作者提出了一种基于patch投影的客观PCQA模型。然后使用已建立的图像质量评估技术(如SSIM[37]和VIF[38])整合从这些投影图像补丁中提取的几何和纹理特征。

整个过程包括两个部分，即patch生成和质量预测。在patch生成中，将参考点云和失真点云分别转换为两幅几何图像和两幅纹理图像，每幅图像都包含不重叠的patch。图里描述了参考点云的3D到2D补丁投影过程。对于补丁生成中的参考点云，可以根据法向量方向对三维点进行聚类，并对连通分量进行分割，从而得到补丁。然后在填充过程中将所有的patch插入到一个空白图像网格中，生成一个几何图像和一个纹理图像。但是由于几何变形可能会改变位置和法向量，因此patch过程中生成的失真点云的斑块可能与参考点云的斑块不同。图中的第一列和第二列分别显示了从参考点云和失真点云中获得的纹理图像和几何图像。可以观察到，由参考生成的图像与失真的点云之间存在明显的不匹配。这些不匹配导致传统的全参考二维IQA方法不再适用于失真点云的几何和纹理图像。为了解决这一不匹配问题，设计了一种基于点匹配的失真点云补丁生成方法。图13中的第三列显示了使用这个方法从失真的点云生成的几何图像和纹理图像。我们可以发现第三列的补丁与第一列的补丁匹配得很精确。因此，我们可以**使用传统的二维IQAs**进行质量预测。在质量预测中，分别这些IQA指标对几何图像和纹理图像进行评价，然后将几何图像和纹理图像的质量分数进行相加融合，得到最终的质量分数。

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408161131419.png" alt="image-20240408161131419" style="zoom:50%;" />

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408161333493.png" alt="image-20240408161333493" style="zoom:50%;" />

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408161355874.png" alt="image-20240408161355874" style="zoom: 50%;" />

5、Point Cloud Quality Assessment using 3D Saliency Maps (使用3D显著性地图的点云质量评估)使用**显著性图**来促进质量预测。

这是第⼀个利用显著性信息的 FR-PCQA 指标来促进质量预测，它使用投影将图像显著性检测的成果转移到PC上，称为使用3D显著性地图的点云质量评估(PQSM)。

具体来说，首先提出了一种基于投影的点云显著性图生成方法，该方法引入深度信息以更好地反映点云的几何特征。下图绿色方框显示了3D显著性图的生成，包括3D到2D投影，深度图和2D显著性图的生成，以及2D到3D的再投影。上面的粉色方框展示了整个PQSM，（包括邻域构建、相似度测量和池化策略）。我们构建点云局部邻域，得到三种结构描述符来表示几何、颜色和显著性差异。最后，提出了一种基于显著性的池化策略来生成最终的质量分数

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408162209320.png" alt="image-20240408162209320" style="zoom: 50%;" />

## 无参考质量评估

虽然这些FR方法取得了良好的效果，需要全解码，耗时长，不适合实际PC传输系统中网络节点的实时质量监控。

1、目前，基于无参考的3D点云质量评估方法主要可以分为两类：基于深度学习的方法和基于比特流的方法。

2、基于深度学习的这些模型通常使用卷积神经网络（CNN）或深度神经网络（RNN）基于图卷积网络（GCN）等深度学习算法，参考IQA，引入了自然场景统计进行评估。

3、基于比特流的这些模型，该方法的主要思想是将点云数据转换为比特流，然后对比特流进行分析，从而得到点云的质量评估结果。

### 基于深度学习的方法

#### IQA-PCQA（未完全分类，包括非图像的方法）

1、PQA-Net : Deep No Reference Point Cloud Quality Assessment via Multi-View Projection 这是第一个针对点云的NR质量评估方法，还首次将深度神经网络引入点云质量评价中，克服了小样本数据的局限性。 通过从多个视图提取和融合特征，识别失真类型，并预测质量向量。由基于多视图的联合特征提取与融合(MVFEF)模块、失真类型识别(DTI)模块和质量向量预测(QVP)模块组成。 DTI和QVP模块共享由MVFEF模块生成的特性。通过使用失真类型标签，首先对DTI和MVFEF模块进行预训练，初始化网络参数，然后在此基础上对整个网络进行联合训练，最终对点云质量进行评价。

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408170520634.png" alt="image-20240408170520634" style="zoom:33%;" />

2、No-reference quality assessment for 3D colored point cloud and mesh models（三维彩色点云和网格模型的无参考质量评估）提出了一种由PC和mesh同时表示的彩色3D模型的度量。首先，我们将3D模型从3D空间投影到与质量相关的几何和颜色特征域。参考自然场景统计(NSS)在IQA任务中取得巨大成功，提取手工制作的特征并估计具有一定NSS分布的统计参数作为质量感知信息。因此，我们选择熵和几种NSS模型，包括广义高斯分布(GGD)、一般非对称广义高斯分布(AGGD)和形状率伽玛分布进行参数估计，以量化三维模型的感知质量。最后，采用支持向量回归(SVR)模型将质量感知特征回归为视觉质量分数。

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408170613523.png" alt="image-20240408170613523" style="zoom:33%;" />

3、Blind quality assessment of 3D dense point clouds with structure guided resampling（基于结构引导重采样的三维密集点云质量盲评估）考虑到人视觉系统对**结构信息**高度敏感。提出了一种基于**结构引导重采样SGR)的PC质量指标，用于自动评估三维密集PC的感知视觉质量。同时也**考虑了自然场景统计(NSS)。

区域预处理。其中涉及关键点重采样和局部区域构建。首先通过法向量对测试点云进行重采样，得到一系列关键点，然后以关键点为中心构建局部区域。

然后，受三维几何及其相关属性的综合影响，利用3组质量感知特征

(1)角度一致性特征

(2)几何密度特征

(3)颜色自然度特征

(4)此外，考虑了自然场景统计(NSS)的基本理论提取的特征。

最后，通过质量回归模块将相关特征映射到最终的质量分数上。选择了普遍的支持向量回归(SVR)和随机森林回归(RFR)，在IQA任务中，它们也被广泛应用于空域和变换域NSS。

<img src="C:\Users\86157\Documents\WeChat Files\wxid_ec12rq8qu3kx22\FileStorage\Temp\1712567283227.png" alt="1712567283227" style="zoom: 50%;" />

4、No-reference point cloud quality assessment via domain adaptation）(基于域自适应的无参考点云质量评估) ，建议利用无监督对抗域自适应(UADA)来解决无参考PCQA，提出了一种用于3DPC的度量，即图像传输点云质量评估(IT-PCQA)。

人类的视觉系统(HVS)是决策者，利用自然图像丰富的主观评分，我们可以通过深度神经网络寻求人类感知的评价标准，并将预测能力转移到三维点云。

将自然图像作为源域，点云作为目标域，通过继承图像领域的先验知识来推断点云质量。

（1）我们首先使用六垂直投影生成点云的多透视纹理图像。

（2）然后，我们设计了一个有效的特征生成器，即分层SCNN (H-SCNN)，将图像送入H-SCNN生成潜在特征。与原始SCNN仅使用单个尺度特征相比，本文提出的H-SCNN融合了层次特征。

（3）接下来，条件判别网络可以连接特征生成网络和质量回归网络，条件判别网络对源域和目标域的特征分布进行匹配，并对特征进行细化，使其更接近客观得分回归。考虑到我们模型的最终目的是质量评估，而不是简单地最小化域差异，我们提出了条件鉴别网络的条件交叉熵损失(CCEL)。在减少域差异的同时，我们惩罚了与质量回归不太相关的特征，并改进了最终结果。

（4）最后，质量回归网络使用两个全连接层来回归由特征生成网络G和条件判别网络D共同生成的潜在特征的客观分数。

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408171047723.png" alt="image-20240408171047723" style="zoom:33%;" />

5、Zoom to Perceive Better: No-reference Point Cloud Quality Assessment via Exploring Effective Multiscale Feature 放大感知更好:无参考点云质量评估通过探索有效的多尺度特征

 提出了一种新的多尺度变观测距离NR-PCQA特征提取和学习模型(MOD-PCQA)，是第一个专门关注视点变化来评估点云质量的研究。随着视点距离的变化，可以分别从具有粗粒度特征的远视点和具有细粒度特征的近视点学习多尺度或多粒度特征。模型结构与工作原理：框架分为三部分，预处理、特征提取和回归部分以及特征学习部分。首先，从不同方向和视角距离获取3D点云的投影2D图像。其次，通过三个特征提取分支网络计算不同视角下的投影图像，以分别从远距离和近距离的视角提取多尺度或多粒度的特征。通过尺度内特征学习的直接质量评估损失和尺度间特征学习的余弦相似度损失来优化每个特征提取网络。

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408162622123.png" alt="image-20240408162622123" style="zoom:50%;" />

**上面这些方法通常是通过预处理获得整个点云的投影二维图像或整个点云的少数特征作为网络的输入，而不是直接使用点云。**

6、ResSCNN： Point Cloud Quality Assessment: Dataset Construction and Learning-based No-Reference Metric点云质量评估:数据集构建和基于学习的无参考度量。受层次感知系统的启发，考虑点云的内在属性，提出了一种基于稀疏卷积神经网络(CNN)的NR度量ResSCNN，**直接从三维点云中提取层次特征**，**同时考虑几何和纹理信息**，来准确估计点云的主观质量。

ResSCNN的架构由三个模块组成：层次特征提取模块、池化和级联模块和质量预测模块：

(a)将完整的三维点云输入到网络中，以避免降维技术带来的额外扭曲。

(b)从设计好的稀疏CNN中提取层次特征，避免了常规密集卷积后特征映射元素大量增加的问题。

(c)将提取的特征进行池化、串联，生成形状固定的特征向量。

(d)质量预测模块使用全连接层的串联将特征向量映射到预测的质量分数。

ResSCNN直接使用整个点云作为输入，但为了节省计算量，采用了稀疏卷积，降低了计算精度。

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408171419082.png" alt="image-20240408171419082" style="zoom:33%;" />

6、No-Reference Point Cloud Quality Assessment via Weighted Patch Quality Prediction（基于加权补丁质量预测的无参考点云质量评估）为了利用质量分布不平衡的优势，提出了一种具有局部相关分析能力的无参考点云质量评价(NR-PCQA)方法，称为COPP-Net。

总体架构包括预处理、特征生成和质量分数预测模块。

（1）使用FPS和KNN算法获得指定数量、指定大小的patch，为每个小块生成纹理和结构特征，并将它们融合到小块特征中，以预测小块的质量。

（2）然后，我们收集点云的所有补丁的特征进行相关分析，中间的特征生成模块包含两个并行的ARKP网络，分别命名为ARKPt（纹理特征生成器）和ARKPs（结构特征生成器），得到相关权值。

（3）最后，使用所有补丁的预测质量和相关权重,使用加权平均方法得出最终的质量分数。

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408171604214.png" alt="image-20240408171604214" style="zoom:33%;" />

7、GPA-Net: No-Reference Point Cloud Quality Assessment with Multi-task Graph Convolutional Network（GPA-Net:无参考点云质量评估与多任务图卷积网络）提出了一种无参考点云质量评估与多任务图卷积网络，称为图卷积PCQA网络(GPA-Net)。它由两个部分组成，即GPA编码器和多任务解码器。GPA编码器由5个GPA层组成，每个GPA层包含3个模块，即采样分组模块、（坐标归一化模块和GPAConv模块）。为了提取有效的PCQA特征，提出了一种新的图卷积核，即GPAConv，它能够捕捉结构和纹理的扰动。然后提出了一个坐标归一化模块来稳定GPAConv在平移、缩放和旋转变换下的结果。多任务解码器由一个信道最大池模块和3个全连接层组成。是由一个主任务(质量回归)和两个辅助任务(扭曲类型和程度预测)组成的多任务框架。

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408171739101.png" alt="image-20240408171739101" style="zoom:33%;" />

#### VQA-PCQA

A No-reference Quality Assessment Metric for Point Cloud Based on Captured Video Sequences

Evaluating Point Cloud from Moving Camera Videos: A No-Reference Metric

这两篇文献的作者相同，他使用的这两种方法的流程大致相同，都包括视频采集模块、 特征提取模块和特征回归模块。

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408191905350.png" alt="image-20240408191905350" style="zoom:33%;" />

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408191917229.png" alt="image-20240408191917229" style="zoom:33%;" />

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408191946709.png" alt="image-20240408191946709" style="zoom:33%;" />

在视频采集模块中，采用的是通过三个特定的轨道围绕点云旋转摄像机获得 三个视频序列。给定一个点云 P，我们使用 Python 包 open3d 获得相应的视频序列。其 中 Capture(·)为视频生成过程。具体来说，摄像机首先被放置在 open3d 可视化函数 计算出的默认位置。

前者：（1）相机在捕获当前帧后，围绕相应轨道上的中心旋转1.71◦~~（12◦）~~以捕获下一帧。因此，总共得到360/1.71=210~~（360/12=30）~~帧来覆盖每个圆轨道。对于一个点云，生成三~~（四）~~个视频序列，总共包含630=210×3帧~~（120=30×4帧）~~。描述了从每个视频序列中提取帧的过程。在训练阶段，在第一帧和第七帧之间随机选择一帧作为开始帧。然后我们以7帧为间隔提取以下帧，得到总共210/7 = 30帧作为输入序列P Vin。

在特征提取模块中，采用带有4个残差层的ResNet3D作为特征提取模型。ResNet3D利用3D卷积从视频中提取特征，能够同时利用时间和空间信息。

特征提取模块完成后，采用由128个神经元组成的全连接(FC)层作为回归模型。另外，将三个视频序列P VA、P VB和P VC标记为训练阶段点云的相同质量分数。将三个视频序列的平均分数记录为测试阶段的预测分数。

后者：（2)将连续帧之间的摄像机旋转步长设置为12◦。然后捕获360/12 = 30帧的片段来覆盖每条圆形路径，得到一个由4个片段和4×30 = 120帧组成的视频用于点云。此外，摄像机在对每个路径进行采样帧后返回到相同的起始位置，因此，捕获的视频在片段之间是连续的。

相比之下，四轨道这篇采用了2D和3D相结合的方法，照上面描述的视频捕获过程，可以得到一个视频序列V，它有四个片段{Ci} 4 i=1，每个片段由30帧组成。然后选取每个单片段Ci中选取的关键帧K ， 利用可训练的ResNet50（2D-CNN）从关键帧中提取空间特征进行空间特征提取，选取每个完整单片段Ci利用预训练的SlowFast R50模型（3D-CNN，只使用快路径）从视频片段中提取时间特征。分别进行时间特征提取。由于空间特征和时间特征的输出通道数量通常不同，因此采用线性投影对通道数量进行对齐。然后将空间特征和时间特征连接起来，形成最终的质量感知特征。

采用了两个阶段的全连接（FC）层，分别包含128个神经元和1个神经元，用于特征回归的过程。考虑到每个视频包含四个片段，我们通过平均池化生成整体质量分数。

损失函数均采用的是均方误差。

### 基于比特流的方法

Bitstream-Based Perceptual Quality Assessment of Compressed 3D Point Clouds（基于比特流的压缩三维点云感知质量评估）首次尝试开发一种基于比特流的无参考(NR)模型，用于G-PCC编码点云的感知质量评估，而无需对压缩数据流进行完全解码。streamPCQ模型如图所示，通过比特流分析仪提取编码参数，包括Trisoup节点大小(TNS)、纹理量化参数(Qp)和纹理比特率(Rp)，然后基于纹理复杂度和量化参数构建**纹理失真评估模型**。将该纹理失真模型与基于Trisoup几何编码参数的几何失真模型相结合，最终得到整体的streamPCQ质量预测。

（在WPC数据库上进行测试时，所提出的streamPCQ模型以极低的计算复杂度展示了最先进的质量预测性能。）

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20240408171909059.png" alt="image-20240408171909059" style="zoom:33%;" />
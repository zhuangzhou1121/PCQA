# 4.16组会问题

**问题一：**单纯拿三个分支网络结构直接用来捕捉不同类型的特征，如何将这些特征进行有效融合？除了attention之外，现在有很多种变种的**数字图像的特征融合的技术**。可以去好好去挖掘一下，在这方面也可以去把它做得更好一点。

你去可以看有好多是CNN跟transformer去融合的网络。你可以去看一看。这个是我给你的一个建议，在注意力这一块也去看一看。

即：

**1**、特征融合网络：使用额外的神经网络模型来学习如何融合不同分支网络的特征。例如，可以使用一个小型的神经网络来学习如何动态地对各个分支网络的特征进行加权融合，这种方法更加灵活，可以根据数据自动调整融合策略。

**2**、注意力机制：使用注意力机制来动态地给不同分支网络的特征赋予不同的权重。通过学习注意力权重，可以更好地捕捉到每个分支网络的重要性，从而更有效地融合特征。

**问题二：**视觉任务都是在质量任务。不一定要在质量任务上去做，比如说这里面我觉得。如果你的d非常小，你半径很小，离着比较远的时候。你可能更希望找到的是这个东西是什么东西，它在干什么？它更多的是一种语义上的判别。它可以是做**分类任务失真类型任务。**然后你离得比较近的时候，你看到的是更多的细节。你有可能这块有空洞？有出来的噪声？然后有不规则的失真。那其实这块你可以用的是什么，是用的**重建技术**。或者是**去噪网络**？那这样的话，你学的是一个重建的任务。但是这些任务之间，它是有关系的。能不能把这几个任务一起去学联合去训练，这样的话会不会对你的整个的novelty会更新？是我想到的比较好的一个idea。当然如果你觉得有难度，你可以后面再做也行。你从前面简单的开始做。这个idea我是觉得比较不错的。后面也会有人去写。因为其实你很容易去想一个东西我们离远的时候，你肯定看它的分辨率比较低，你看不到很多细节，你更多的是看这个人在干。实战类型可能是什么样子的？这个场景，它的分类是什么样子的，它类别是什么？如果你这个东西离得近了，你就会看它的细节的东西，哪些是噪声？这些都是渠道网络要做的事情。你可以用不同的网络结构去做。有的是做分类的任务的网络，有的是用去噪的网络，觉得任务也可以不一样，在于训练的时候。你可联合训练的时候，你做用联合训练，你也可以让他去用预训练的网络，然后把特征拿出来再做融合。这样的话你的？整个的novelty应该比之前还会新。

即：

不同的距离尺度下可以做不同的视觉任务。（d2＞d1＞d0）

1、 d0距离下,可以做重建技术或者去噪网络。

2、 d2距离下，更多是语义上的判别，可以做分类任务、失真任务。

这些任务之间是有关系的，能不能把这几个任务一起去联合训练？

**问题三：**你用了不同的d，得到了数据量是可能以前的很多倍？以为基准的话，你可能得到的数据量是以前的N倍。因为你这后面太多了。这里面你有没有想过一种方法，我能不能去用什么样的方法往数据量虽然是增倍了，我能不能用采样的方式把这些数据进行一个有效的采样。让他训练的时候更快。降低复杂度。甚至这个D我可能取更多，但是我可能还要取好几个D但是我整个的数据量我是采样的，你就比如说。像那种Fast-VQA一样，你去这样采样？对所以其实也是一个好的idea。包括你可能是正面的拍摄的resolution那我能不能侧面的多几个？我能不能调换角度？等等这些都是你可以去。就想了我觉得你想做你现在。你说你想做，因为你刚入门想做一个简单一点的，我觉得也没有问题。

即：

使用N种不同的距离，将每个分支网络输出的特征拼接在一起，形成一个更大的特征向量。这种方法简单直观，但是得到的数据量可能是以前的N倍，可能会导致特征空间过于庞大，增加了计算和存储成本。

解决方法：类似于Fast-VQA一样，整个的数据量采样。包括可以调换拍摄的角度与面数。

------



# 如何将三分支网络进行融合操作？

1. **拼接**（Concatenation）：将每个分支网络输出的特征拼接在一起，形成一个更大的特征向量。这种方法简单直观，但可能会导致特征空间过于庞大，增加了计算和存储成本。

2. ~~**逐元素加法或减法**：对应位置上的特征进行加法或减法操作。这种方法可以将不同分支网络的特征进行加权融合，但需要保证特征维度相同。~~

3. **特征融合网络**：使用额外的神经网络模型来学习如何融合不同分支网络的特征。例如，可以使用一个小型的神经网络来学习如何动态地对各个分支网络的特征进行加权融合，这种方法更加灵活，可以根据数据自动调整融合策略。

4. **注意力机制**：使用注意力机制来动态地给不同分支网络的特征赋予不同的权重。通过学习注意力权重，可以更好地捕捉到每个分支网络的重要性，从而更有效地融合特征。

5. **降维**：可以使用主成分分析（PCA）等技术对特征进行降维，然后再进行融合操作。这有助于减少特征的维度，提高计算效率。

（为什么使用降维？将每个分支网络输出的特征拼接在一起，形成一个更大的特征向量。这种方法简单直观，但可能会导致特征空间过于庞大，增加了计算和存储成本。） 

6. **集成学习（MOD-PCQA模型所使用）**：将不同分支网络的输出看作是不同的模型，然后使用集成学习方法（如投票、平均）来融合它们的预测结果。这种方法可以通过结合多个模型的优势来提高整体性能。

（集成学习中的平均方法通常是将每个分支的预测结果（例如分类器的输出概率、回归器的预测值等）加起来，然后除以分支的总数，以得到最终的集成预测结果。这种方法被称为简单平均（Simple Averaging）或者均值投票（Mean Voting）。）

------



# 如何结合拼接特征与注意力机制？

这两种方法都可以**在拼接和注意力机制之间建立有效的联系**，以充分利用各个分支网络的信息，并根据不同特征的重要性动态地调整特征的融合方式。

1.**拼接后应用注意力机制**：首先将每个分支网络的特征拼接在一起，形成一个更大的特征向量。然后，将拼接后的特征输入到注意力机制中，注意力机制可以学习不同特征之间的关系，并为每个特征赋予不同的权重，以强调重要的特征。 

2.**注意力机制引导拼接**：首先，对每个分支网络的特征进行注意力加权，得到加权后的特征表示。然后，将加权后的特征表示进行拼接，形成一个更大的特征向量。这样做可以在拼接之前，根据不同特征的重要性进行加权处理，以提高拼接后特征的质量。

------



# 如何结合拼接特征、降维、注意力机制和集成学习？

1. **拼接特征**：首先，将每个分支网络输出的特征拼接在一起，形成一个更大的特征向量。

2. **降维**：对拼接后的特征向量进行降维操作，以减少特征的数量和复杂度。可以使用主成分分析（PCA）、判别分析（LDA）等方法进行降维。

3. **注意力机制**：对降维后的特征向量应用注意力机制，以动态地为不同特征赋予权重。注意力机制可以学习到每个特征的重要性，并对其进行加权，以便更好地捕获关键信息。

4. **集成学习**：对应用注意力机制后的特征向量进行集成学习。采用简单平均的方法，将各个分支网络的输出进行加权平均，得到最终的集成预测结果。这样可以综合考虑每个分支网络的贡献，并减少过拟合的风险。

下面是一个简单的示例代码：

````
```python
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import VotingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import numpy as np

# 假设有三个分支网络的输出，每个输出是一个20维的特征向量
branch1_output = np.random.rand(100, 20)
branch2_output = np.random.rand(100, 20)
branch3_output = np.random.rand(100, 20)

# 拼接特征
concatenated_features = np.concatenate((branch1_output, branch2_output, branch3_output), axis=1)

# 标准化数据
scaler = StandardScaler()
scaled_features = scaler.fit_transform(concatenated_features)

# PCA降维
pca = PCA(n_components=10)
reduced_features = pca.fit_transform(scaled_features)

# 应用注意力机制
# 假设在这里实现注意力机制

# 集成学习
# 假设使用线性回归模型作为基本模型
model1 = LinearRegression()
model2 = LinearRegression()
model3 = LinearRegression()

# 创建集成模型
ensemble_model = VotingRegressor([('model1', model1), ('model2', model2), ('model3', model3)])

# 拟合集成模型
ensemble_model.fit(reduced_features, y_true)

# 预测
y_pred = ensemble_model.predict(reduced_features)

# 评估模型性能
mse = mean_squared_error(y_true, y_pred)
print("Mean Squared Error:", mse)
```
````

这段代码首先将三个分支网络的输出特征拼接在一起，然后对拼接后的特征进行标准化和降维。接着应用注意力机制（在代码中略去了实现部分），最后使用集成学习（这里使用投票回归器）进行模型集成。

------



# 注意力机制分类

注意力机制是一种用于模型学习和处理序列数据时重要的技术，它可以使模型动态地关注到输入数据中的不同部分，从而提高模型的性能和泛化能力。以下是一些常见的注意力机制：

1. Sigmoid Attention：通过对每个输入位置的特征进行加权，生成一个注意力分布，用于对输入序列进行加权求和。它通过对注意力权重进行sigmoid激活，将注意力分布限制在0到1之间，以确保每个位置的注意力权重在合理的范围内。

2. Softmax Attention：是一种常见的注意力机制，它将注意力权重通过softmax函数进行归一化，使得所有位置的注意力权重之和为1。Softmax Attention可以用于计算每个位置的权重，并将其应用于输入序列的加权求和。

3. Scaled Dot-Product Attention：是一种用于计算注意力权重的机制，它将查询向量和键向量进行点积操作，然后通过缩放因子进行归一化，最后将注意力权重应用于值向量上。Scaled Dot-Product Attention具有高效的计算性能和良好的数值稳定性，常用于Transformer模型等。

4. **Self-Attention**：是一种特殊的注意力机制，用于计算输入序列内部的注意力关系。在Self-Attention中，查询、键和值都来自同一个输入序列，模型可以学习到序列内部的依赖关系，从而更好地捕获序列中的长程依赖关系。

5. Multi-Head Attention：Multi-Head Attention是一种多头注意力机制，通过多个注意力头并行计算多组注意力权重，然后将它们进行拼接或加权求和，以获得更丰富和更准确的注意力表示。Multi-Head Attention可以增强模型的表达能力和学习能力，常用于Transformer等模型中。

   ------

   

# Self-Attention（引入空间注意力）（建议使用）

引入空间注意力,使用Self-Attention机制的原因：

1、 在注意力机制中引入空间注意力，使得模型在融合特征时不仅考虑通道间的相关性，还考虑空间位置上的相关性。这样做可以使模型更加关注图像中与任务相关的局部区域，提高特征的表达能力和判别能力。

2、 由于点云数据具有空间结构和局部关联性，Self-Attention机制可以帮助模型动态地学习到点云数据内部的依赖关系和重要特征。通过Self-Attention机制，模型可以自动学习到每个点之间的关联程度，从而更好地捕获点云数据的全局和局部特征。（与第一条原因大概一样）

3、 要处理的是点云数据，并且已经使用了多个分支网络（CNN、Res2Net、Transformer）来提取特征，建议使用Self-Attention机制可能会更合适。

4、 Self-Attention机制可以在输入序列内部计算注意力关系，因此不需要额外的查询向量和键向量，可以直接应用于点云数据的特征表示，简化了模型的结构和计算过程。

------



# 损失函数

1. **综合损失函数**：可以使用平均绝对误差（MAE）和均方误差（MSE）的组合来衡量预测值和真实值之间的差异，然后将它们结合起来作为总体损失。

将 gap loss 和 rank loss 保留在训练过程中，因为它们有助于模型学习和优化。这些损失函数有助于模型更好地理解和预测点云的质量。

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image002.jpg)

N：一个小批量中点云样本的数量

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image004.png)预测得分

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image006.png)：MOS

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image008.png)：预测得分均值

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image010.png)：实际得分的均值，

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image012.jpg)

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image014.png)：小批量中两个点云k和l之间的rank loss。

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image016.png)

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image018.png)

𝛼、𝛽 、𝛾：损失函数的权重系数，根据训练过程中的需求进行调整。

 

2. **注意力增强的交叉熵损失**：在注意力机制的基础上增强交叉熵损失，让模型更关注重要特征。

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image020.png)=-![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image022.png)

N：样本数量

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image006.png)：第i个样本的mos

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image024.png)：模型对第 i 个样本的预测分数

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image026.png)：注意力模块对第 i个样本的注意力权重

 

3. ~~**对抗性损失函数**（若引入对抗性生成网络（GANs），那么适用）：引入对抗性损失，以提高模型对对抗样本的鲁棒性。~~

 

3. **多尺度损失函数**：将不同尺度的预测结果纳入损失函数，综合考虑多尺度信息。

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image028.png)

S：尺度的数量

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image030.png)：各个尺度损失的权重

![img](file:///C:/Users/86157/AppData/Local/Temp/msohtmlclip1/01/clip_image032.png)：第s个尺度的损失函数

------



# 计算与训练方法

**计算与训练算法：**

 

**输入：**点云数据P和对应的真实质量分数 y；

**输出：**经过训练优化后的点云质量评估模型；

 

   1．**初始化参数：**初始化模型参数、权重和偏差；

2. **训练模型：**对于每个epoch进行以下步骤：

​        a.  **获取投影图像集：**

​               i.  根据不同观察位置获取点云数据的投影图像集；

​               ii. 对 d0 距离下的点云数据使用采样 patch 方法转换为图像数据，以便输入到Transformer模型中；

​        b.  **特征提取：**对于每个距离尺度，进行如下操作：

​               i.  **特征提取：**将每个距离尺度下的图像输入到对应的分支网络中进行特征提取，分别为 CNN、Res2Net 和 Transformer；

​              ii. **特征拼接：**将三个分支网络提取的特征拼接在一起，形成一个整体的特征向量；

​       c.  **降维处理：**对总特征进行降维处理，将其转换为更低维度的表示，融合为单一特征向量；

​       d.  **注意力加权：**使用注意力机制对特征进行加权处理； 

​       e.  **预测得分：**将加权后的特征输入到全连接层中进行预测得分；

​       f.  **计算损失函数：**计算综合预测结果与真实质量标签之间的损失，包括综合损失、注意力增强的交叉熵损失和多尺度损失函数；

​      g.  **计算梯度：**使用反向传播算法计算各个损失函数的梯度；

​      h.  **更新参数：**更新模型参数；   

3. **输出模型：**经过训练优化后的点云质量评估模型。